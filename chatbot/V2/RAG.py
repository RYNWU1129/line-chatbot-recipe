import os
import json
import pandas as pd
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import openai
import firebase_admin
from firebase_admin import credentials, firestore

# ----------------------------------------- 
# ğŸ”¹ åˆå§‹åŒ–å…¨å±€è®Šæ•¸
# ----------------------------------------- 
FAISS_INDEX_PATH = "recipe_faiss.index"
METADATA_PATH = "recipe_metadata.csv"

# å…¨å±€è®Šæ•¸
index = None
df = None

# âœ… å¾ç’°å¢ƒè®Šæ•¸è®€å– API Keys
openai_api_key = os.getenv("OPENAI_API_KEY")
firebase_json = os.getenv("FIREBASE_CREDENTIALS")

if not openai_api_key:
    raise ValueError("âŒ OPENAI_API_KEY not found! Please set it in Render environment variables.")

# âœ… åˆå§‹åŒ– Firebaseï¼ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼‰
if firebase_json:
    firebase_cred = json.loads(firebase_json)  # è§£æ JSON å­—ä¸²
    if not firebase_admin._apps:  # ç¢ºä¿ Firebase åªåˆå§‹åŒ–ä¸€æ¬¡
        cred = credentials.Certificate(firebase_cred)
        firebase_admin.initialize_app(cred)
else:
    raise ValueError("âŒ FIREBASE_CREDENTIALS not found! Please set it in Render environment variables.")

db = firestore.client()

# âœ… åŠ è¼‰ embedding æ¨¡å‹
model = SentenceTransformer("all-MiniLM-L6-v2")

# ----------------------------------------- 
# ğŸ”¹ RAG åˆå§‹åŒ–å‡½æ•¸ (ç”¨æ–¼èƒŒæ™¯åŸ·è¡Œ)
# ----------------------------------------- 
def initialize_rag():
    """åˆå§‹åŒ– RAG ç³»çµ±ï¼ŒåŠ è¼‰é è™•ç†çš„ FAISS ç´¢å¼•å’Œå…ƒæ•¸æ“š"""
    global index, df
    
    print("ğŸ” é–‹å§‹åˆå§‹åŒ– RAG ç³»çµ±...")
    
    if os.path.exists(FAISS_INDEX_PATH) and os.path.exists(METADATA_PATH):
        print("âœ… æ‰¾åˆ°é è™•ç†çš„ FAISS ç´¢å¼•å’Œå…ƒæ•¸æ“šï¼Œç›´æ¥è¼‰å…¥")
        index = faiss.read_index(FAISS_INDEX_PATH)
        df = pd.read_csv(METADATA_PATH)
        print("âœ… RAG ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
        return index, df
    else:
        error_msg = f"âŒ æ‰¾ä¸åˆ°é è™•ç†çš„ç´¢å¼•æ–‡ä»¶ï¼åœ¨ {os.getcwd()} ä¸­å°‹æ‰¾ {FAISS_INDEX_PATH} å’Œ {METADATA_PATH} å¤±æ•—ã€‚"
        print(error_msg)
        # åˆ—å‡ºç•¶å‰ç›®éŒ„å…§å®¹ï¼Œç”¨æ–¼èª¿è©¦
        print("ç›®éŒ„å…§å®¹:", os.listdir("."))
        raise FileNotFoundError(error_msg)

# ----------------------------------------- 
# ğŸ”¹ Firestore å‡½æ•¸
# ----------------------------------------- 
def get_user_data(user_id):
    """ å¾ Firestore ç²å–ä½¿ç”¨è€…æ•¸æ“š """
    try:
        user_ref = db.collection("users").document(user_id)
        user_doc = user_ref.get()
        return user_doc.to_dict() if user_doc.exists else None
    except Exception as e:
        print(f"âŒ Firestore ç²å–ç”¨æˆ¶æ•¸æ“šéŒ¯èª¤: {e}")
        return None

def set_user_data(user_id, data):
    """ æ›´æ–° Firestore ä¸­çš„ä½¿ç”¨è€…æ•¸æ“š """
    try:
        user_ref = db.collection("users").document(user_id)
        user_ref.set(data, merge=True)
        return True
    except Exception as e:
        print(f"âŒ Firestore è¨­ç½®ç”¨æˆ¶æ•¸æ“šéŒ¯èª¤: {e}")
        return False

def get_user_conversation(user_id):
    """ ç²å–ä½¿ç”¨è€…çš„èŠå¤©è¨˜éŒ„ """
    try:
        user_ref = db.collection("conversations").document(user_id)
        user_doc = user_ref.get()
        return user_doc.to_dict().get("messages", []) if user_doc.exists else []
    except Exception as e:
        print(f"âŒ Firestore ç²å–å°è©±è¨˜éŒ„éŒ¯èª¤: {e}")
        return []

def save_user_conversation(user_id, messages):
    """ å­˜å„²ä½¿ç”¨è€…çš„èŠå¤©è¨˜éŒ„ """
    try:
        user_ref = db.collection("conversations").document(user_id)
        user_ref.set({"messages": messages}, merge=True)
        return True
    except Exception as e:
        print(f"âŒ Firestore ä¿å­˜å°è©±è¨˜éŒ„éŒ¯èª¤: {e}")
        return False

# ----------------------------------------- 
# ğŸ”¹ FAISS æª¢ç´¢
# ----------------------------------------- 
def search_recipe(query, k=3):
    """ é€é FAISS æœå°‹ç›¸ä¼¼é£Ÿè­œ """
    global index, df
    
    # ç¢ºä¿ index å’Œ df å·²åˆå§‹åŒ–
    if index is None or df is None:
        print("âš ï¸ FAISS ç´¢å¼•å’Œå…ƒæ•¸æ“šæœªåˆå§‹åŒ–ï¼Œå˜—è©¦åˆå§‹åŒ–...")
        initialize_rag()
    
    try:
        query_embedding = model.encode(query, convert_to_numpy=True).reshape(1, -1)
        distances, indices = index.search(query_embedding, k)
        return df.iloc[indices[0]]
    except Exception as e:
        print(f"âŒ FAISS æª¢ç´¢éŒ¯èª¤: {e}")
        return None

# ----------------------------------------- 
# ğŸ”¹ GPT æ•´åˆ
# ----------------------------------------- 
def chat_with_model(user_id, user_input):
    """ GPT ç”Ÿæˆå›æ‡‰ä¸¦æ•´åˆ FAISS æœå°‹çµæœ """
    global index, df
    
    print(f"ğŸ“ è™•ç†ç”¨æˆ¶ {user_id} çš„è¼¸å…¥: {user_input}")
    
    # ç¢ºä¿ RAG ç³»çµ±å·²åˆå§‹åŒ–
    if index is None or df is None:
        print("âš ï¸ åœ¨ä½¿ç”¨èŠå¤©æ¨¡å‹å‰ï¼Œç¢ºä¿ RAG å·²åˆå§‹åŒ–...")
        try:
            initialize_rag()
        except Exception as e:
            print(f"âŒ RAG åˆå§‹åŒ–å¤±æ•—: {e}")
            return "Sorry, the recipe system is currently initializing. Please try again in a moment."
    
    # ç²å–ç”¨æˆ¶æ•¸æ“š
    user_data = get_user_data(user_id)
    preferences = user_data.get("preferences", None) if user_data else None
    
    # æª¢æŸ¥æ˜¯å¦æ˜¯è¨­ç½®åå¥½çš„è¨Šæ¯
    if not preferences:
        # ä¿å­˜ç”¨æˆ¶åå¥½
        set_user_data(user_id, {"preferences": user_input})
        return f"Thanks! I've noted your dietary preferences: {user_input}. Now you can ask for recipe recommendations!"
    
    # æœå°‹ç›¸é—œé£Ÿè­œ
    print(f"ğŸ” ç‚ºæŸ¥è©¢ '{user_input}' æœå°‹é£Ÿè­œ...")
    best_recipes = search_recipe(user_input, k=3)
    if best_recipes is None or len(best_recipes) == 0:
        return "Sorry, I couldn't find any relevant recipes for your request."
    
    # æ ¼å¼åŒ–é£Ÿè­œçµæœ
    formatted_recipes = "\n\n".join([
        f"**Title:** {row['title']}\n**Ingredients:** {row['ingredients']}\n**Instructions:** {row['directions']}"
        for _, row in best_recipes.iterrows()
    ])
    
    # çµ„ç¹”ç³»çµ±æç¤º
    system_prompt = f"""
    You are a professional chef assistant. The user follows these dietary preferences: {preferences}.
    Here are recommended recipes based on their preferences:
    {formatted_recipes}
    Provide a response considering these preferences strictly.
    """
    
    # ç²å–å°è©±æ­·å²
    conversation = get_user_conversation(user_id)
    if not conversation:
        conversation.append({"role": "system", "content": system_prompt})
    conversation.append({"role": "user", "content": user_input})
    
    # èª¿ç”¨ OpenAI API
    try:
        client = openai.OpenAI(api_key=openai_api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=conversation,
            max_tokens=200
        )
        
        reply = response.choices[0].message.content
        
        # ä¿å­˜å°è©±
        conversation.append({"role": "assistant", "content": reply})
        if len(conversation) > 20:
            conversation = conversation[-20:]
        save_user_conversation(user_id, conversation)
        
        return reply
    except Exception as e:
        print(f"âŒ OpenAI API èª¿ç”¨éŒ¯èª¤: {e}")
        return "Sorry, I'm having trouble connecting to my recipe brain. Please try again later."